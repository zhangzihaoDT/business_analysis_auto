#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
éªŒè¯è®¢å•è§‚å¯Ÿæ•°æ® Parquet æ–‡ä»¶

è¯¥è„šæœ¬ç”¨äºéªŒè¯ç”Ÿæˆçš„ order_observation_data.parquet æ–‡ä»¶
å¹¶æä¾›è¯¦ç»†çš„æ•°æ®æè¿°ä¿¡æ¯
"""

import pandas as pd
import numpy as np
import os

def verify_parquet_file():
    """
    éªŒè¯ Parquet æ–‡ä»¶å¹¶æä¾›æ•°æ®æè¿°
    """
    parquet_file_path = "/Users/zihao_/Documents/coding/dataset/formatted/order_observation_data.parquet"
    
    try:
        print("ğŸ” å¼€å§‹éªŒè¯ Parquet æ–‡ä»¶...")
        print(f"ğŸ“ æ–‡ä»¶è·¯å¾„: {parquet_file_path}")
        
        # 1. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(parquet_file_path):
            print("âŒ Parquet æ–‡ä»¶ä¸å­˜åœ¨ï¼")
            return
        
        # 2. è¯»å– Parquet æ–‡ä»¶
        df = pd.read_parquet(parquet_file_path)
        
        # 3. åŸºæœ¬ä¿¡æ¯
        print("\n" + "="*80)
        print(" åŸºæœ¬æ•°æ®ä¿¡æ¯ ")
        print("="*80)
        print(f"ğŸ“Š æ•°æ®ç»´åº¦: {df.shape[0]} è¡Œ x {df.shape[1]} åˆ—")
        
        # 4. æ–‡ä»¶å¤§å°
        file_size = os.path.getsize(parquet_file_path) / (1024 * 1024)  # MB
        print(f"ğŸ“ æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
        
        # 5. æ•°æ®ç±»å‹ä¿¡æ¯
        print("\n" + "="*80)
        print(" æ•°æ®ç±»å‹ä¿¡æ¯ ")
        print("="*80)
        print(df.dtypes)
        
        # 6. å†…å­˜ä½¿ç”¨æƒ…å†µ
        print("\n" + "="*80)
        print(" å†…å­˜ä½¿ç”¨æƒ…å†µ ")
        print("="*80)
        memory_usage = df.memory_usage(deep=True)
        total_memory = memory_usage.sum() / (1024 * 1024)  # MB
        print(f"æ€»å†…å­˜ä½¿ç”¨: {total_memory:.2f} MB")
        print("\nå„åˆ—å†…å­˜ä½¿ç”¨:")
        for col, usage in memory_usage.items():
            if col != 'Index':
                usage_mb = usage / (1024 * 1024)
                print(f"{col}: {usage_mb:.3f} MB")
        
        # 7. ç©ºå€¼ç»Ÿè®¡
        print("\n" + "="*80)
        print(" ç©ºå€¼ç»Ÿè®¡ ")
        print("="*80)
        null_counts = df.isnull().sum()
        null_stats = []
        for col, count in null_counts.items():
            percentage = (count / len(df)) * 100
            null_stats.append({
                'å­—æ®µå': col,
                'ç©ºå€¼æ•°é‡': count,
                'ç©ºå€¼æ¯”ä¾‹': f"{percentage:.2f}%"
            })
        
        null_df = pd.DataFrame(null_stats)
        print(null_df.to_string(index=False))
        
        # 8. æ•°å€¼å‹å­—æ®µç»Ÿè®¡
        print("\n" + "="*80)
        print(" æ•°å€¼å‹å­—æ®µç»Ÿè®¡ ")
        print("="*80)
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) > 0:
            print(df[numeric_cols].describe())
        else:
            print("æœªå‘ç°æ•°å€¼å‹å­—æ®µ")
        
        # 9. åˆ†ç±»å­—æ®µç»Ÿè®¡
        print("\n" + "="*80)
        print(" åˆ†ç±»å­—æ®µç»Ÿè®¡ ")
        print("="*80)
        categorical_cols = df.select_dtypes(include=['category']).columns
        for col in categorical_cols:
            unique_count = df[col].nunique()
            print(f"\n{col}:")
            print(f"  å”¯ä¸€å€¼æ•°é‡: {unique_count}")
            if unique_count <= 20:  # å¦‚æœå”¯ä¸€å€¼å°‘äºç­‰äº20ä¸ªï¼Œæ˜¾ç¤ºæ‰€æœ‰å€¼
                value_counts = df[col].value_counts()
                print(f"  å€¼åˆ†å¸ƒ:")
                for value, count in value_counts.items():
                    percentage = (count / len(df)) * 100
                    print(f"    {value}: {count} ({percentage:.2f}%)")
            else:
                print(f"  å‰10ä¸ªå€¼:")
                value_counts = df[col].value_counts().head(10)
                for value, count in value_counts.items():
                    percentage = (count / len(df)) * 100
                    print(f"    {value}: {count} ({percentage:.2f}%)")
        
        # 10. æ—¥æœŸå­—æ®µç»Ÿè®¡
        print("\n" + "="*80)
        print(" æ—¥æœŸå­—æ®µç»Ÿè®¡ ")
        print("="*80)
        date_cols = df.select_dtypes(include=['datetime64[ns]']).columns
        for col in date_cols:
            non_null_dates = df[col].dropna()
            if len(non_null_dates) > 0:
                print(f"\n{col}:")
                print(f"  éç©ºè®°å½•æ•°: {len(non_null_dates)}")
                print(f"  æœ€æ—©æ—¥æœŸ: {non_null_dates.min()}")
                print(f"  æœ€æ™šæ—¥æœŸ: {non_null_dates.max()}")
                print(f"  æ—¥æœŸèŒƒå›´: {(non_null_dates.max() - non_null_dates.min()).days} å¤©")
            else:
                print(f"\n{col}: æ— æœ‰æ•ˆæ—¥æœŸæ•°æ®")
        
        # 11. æ•°æ®æ ·æœ¬
        print("\n" + "="*80)
        print(" æ•°æ®æ ·æœ¬ ")
        print("="*80)
        print("å‰5è¡Œæ•°æ®:")
        pd.set_option('display.max_columns', None)
        pd.set_option('display.width', None)
        pd.set_option('display.max_colwidth', 30)
        print(df.head())
        
        # é‡ç½®pandasæ˜¾ç¤ºé€‰é¡¹
        pd.reset_option('display.max_columns')
        pd.reset_option('display.width')
        pd.reset_option('display.max_colwidth')
        
        print("\nâœ… Parquet æ–‡ä»¶éªŒè¯å®Œæˆï¼")
        
        return df
        
    except Exception as e:
        print(f"âŒ éªŒè¯è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        raise e

if __name__ == "__main__":
    # æ‰§è¡ŒéªŒè¯
    try:
        df = verify_parquet_file()
        print("\nğŸ‰ éªŒè¯æˆåŠŸå®Œæˆï¼")
    except Exception as e:
        print(f"\nğŸ’¥ éªŒè¯å¤±è´¥: {e}")