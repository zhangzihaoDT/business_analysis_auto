#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import sys
import argparse
from typing import Optional, List

import pandas as pd


BASE = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
DEFAULT_INPUT = os.path.join(BASE, "original", "leads_assign_city_store2_1.csv")
OUT_DIR = os.path.join(BASE, "processed", "analysis_results")


def load_csv(path: str) -> pd.DataFrame:
    encodings = ["utf-16", "utf-16-le", "utf-8-sig", "utf-8", "gb18030", "latin1"]
    seps = [",", "\t", ";", "|"]
    last_err = None
    for enc in encodings:
        sep_guess = ","
        try:
            with open(path, "r", encoding=enc) as f:
                first = f.readline()
            sep_guess = max(seps, key=lambda s: first.count(s))
        except Exception:
            pass

        try:
            df = pd.read_csv(path, encoding=enc, sep=sep_guess)
            if df.shape[1] > 1:
                return df
        except Exception:
            try:
                df = pd.read_csv(
                    path,
                    encoding=enc,
                    sep=sep_guess,
                    engine="python",
                    on_bad_lines="skip",
                    quotechar='"',
                    escapechar='\\',
                    doublequote=True,
                )
                if df.shape[1] > 1:
                    return df
            except Exception as e2:
                last_err = e2
                continue
    raise RuntimeError(f"æ— æ³•è¯»å–CSV: {path}. æœ€åé”™è¯¯: {last_err}")


def resolve_col(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:
    def norm(s: str) -> str:
        return str(s).strip().lower().replace(" ", "").replace("_", "")

    index = {norm(c): c for c in df.columns}
    for c in candidates:
        if c in df.columns:
            return c
        nc = norm(c)
        if nc in index:
            return index[nc]
    return None


def build_date(df: pd.DataFrame, col_year: Optional[str], col_month: Optional[str], col_day: Optional[str], col_full: Optional[str]) -> pd.Series:
    # 1) Prefer full timestamp column
    if col_full and col_full in df.columns:
        dt = pd.to_datetime(df[col_full], errors="coerce")
        if dt.notna().any():
            return dt.dt.date

    # 2) Try parsing 'day' column directly if it contains full date strings
    if col_day and col_day in df.columns:
        s = df[col_day].astype(str)
        looks_like_date = s.str.contains("-|") | s.str.contains("å¹´")
        if looks_like_date.any():
            dt_try = pd.to_datetime(s.str.replace("å¹´", "-").str.replace("æœˆ", "-").str.replace("æ—¥", ""), errors="coerce")
            if dt_try.notna().any():
                return dt_try.dt.date

    # 3) Compose from year/month/day
    parts = {}
    if col_year and col_year in df.columns:
        parts["year"] = pd.to_numeric(df[col_year], errors="coerce")
    if col_month and col_month in df.columns:
        parts["month"] = pd.to_numeric(df[col_month], errors="coerce")
    if col_day and col_day in df.columns:
        parts["day"] = pd.to_numeric(df[col_day], errors="coerce")
    if {"year", "month", "day"}.issubset(parts.keys()):
        y = parts["year"].fillna(0).astype(int)
        m = parts["month"].fillna(1).astype(int)
        d = parts["day"].fillna(1).astype(int)
        dt = pd.to_datetime(pd.DataFrame({"y": y, "m": m, "d": d}), errors="coerce")
        if dt.notna().any():
            return dt.dt.date

    # 4) Fail: return all-NA series
    return pd.to_datetime(pd.Series([None] * len(df))).dt.date


def pivot_metrics(df: pd.DataFrame, col_city: str, col_region: str, col_date: str, col_metric_name: str, col_metric_value: str) -> pd.DataFrame:
    # Keep only relevant columns
    keep = [col_city, col_region, col_date, col_metric_name, col_metric_value]
    missing = [c for c in keep if c not in df.columns]
    if missing:
        raise KeyError(f"ç¼ºå°‘å¿…è¦åˆ—: {missing}")

    tmp = df[keep].copy()
    # Clean and coerce metric values to numeric
    if tmp[col_metric_value].dtype == object:
        s = tmp[col_metric_value].astype(str)
        s = s.str.replace(",", "", regex=False).str.strip()
        tmp[col_metric_value] = pd.to_numeric(s, errors="coerce")
    else:
        tmp[col_metric_value] = pd.to_numeric(tmp[col_metric_value], errors="coerce")

    # Aggregation rules:
    # - ä¸‹å‘é—¨åº—æ•°: use max per (city, region, date)
    # - çº¿ç´¢è¯†åˆ«æ•°: use sum per (city, region, date)
    idx_cols = [col_city, col_region, col_date]
    assign_df = (
        tmp[tmp[col_metric_name] == "ä¸‹å‘é—¨åº—æ•°"]
        .groupby(idx_cols, as_index=False)[col_metric_value]
        .max()
        .rename(columns={col_metric_value: "ä¸‹å‘é—¨åº—æ•°"})
    )
    identify_df = (
        tmp[tmp[col_metric_name] == "çº¿ç´¢è¯†åˆ«æ•°"]
        .groupby(idx_cols, as_index=False)[col_metric_value]
        .sum()
        .rename(columns={col_metric_value: "çº¿ç´¢è¯†åˆ«æ•°"})
    )

    wide = pd.merge(assign_df, identify_df, on=idx_cols, how="outer").fillna(0)

    # Reorder columns
    wide = wide[[col_city, col_region, col_date, "ä¸‹å‘é—¨åº—æ•°", "çº¿ç´¢è¯†åˆ«æ•°"]]
    # Ensure numeric types
    wide["ä¸‹å‘é—¨åº—æ•°"] = pd.to_numeric(wide["ä¸‹å‘é—¨åº—æ•°"], errors="coerce").fillna(0)
    wide["çº¿ç´¢è¯†åˆ«æ•°"] = pd.to_numeric(wide["çº¿ç´¢è¯†åˆ«æ•°"], errors="coerce").fillna(0)
    return wide


def main(argv: Optional[List[str]] = None) -> int:
    if argv is None:
        argv = sys.argv[1:]

    parser = argparse.ArgumentParser(description="æŒ‰æŒ‡å®šåŒºé—´æ±‡æ€»ä¸‹å‘é—¨åº—æ•°(æŒ‰æ—¥-åŸå–max)ä¸çº¿ç´¢è¯†åˆ«æ•°(å–sum)")
    parser.add_argument("--start", required=True, help="å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼YYYY-MM-DD")
    parser.add_argument("--end", required=True, help="ç»“æŸæ—¥æœŸï¼Œæ ¼å¼YYYY-MM-DD")
    args = parser.parse_args(argv)

    input_path = DEFAULT_INPUT
    start = args.start
    end = args.end

    if not os.path.exists(input_path):
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_path}")
        return 1

    print(f"ğŸ“¥ ä½¿ç”¨å›ºå®šæºæ–‡ä»¶: {input_path}")
    df = load_csv(input_path)
    print(f"ğŸ“Š åŸå§‹ç»´åº¦: {df.shape[0]} è¡Œ Ã— {df.shape[1]} åˆ—")

    # Resolve necessary columns
    col_city = resolve_col(df, ["lc_assign_1st2sales_city_name", "city", "åŸå¸‚"])
    col_region = resolve_col(df, ["lc_assign_1st2sales_region_name", "region", "åŒºåŸŸ"])
    col_day = resolve_col(df, ["æ—¥(lc_assign_time_min)", "lc_assign_time_min æ—¥", "day(lc_assign_time_min)", "day"])
    col_year = resolve_col(df, ["lc_assign_time_min å¹´", "å¹´(lc_assign_time_min)", "year(lc_assign_time_min)", "year"])
    col_month = resolve_col(df, ["lc_assign_time_min æœˆ", "æœˆ(lc_assign_time_min)", "month(lc_assign_time_min)", "month"])
    col_full = resolve_col(df, ["lc_assign_time_min", "assign_time", "æ—¶é—´", "date"])
    col_metric_name = resolve_col(df, ["åº¦é‡åç§°", "Measure Names", "measure_names", "metric_name"])
    col_metric_value = resolve_col(df, ["åº¦é‡å€¼", "Measure Values", "measure_values", "metric_value", "value"])

    if not (col_city and col_region and col_metric_name and col_metric_value):
        print("âŒ å…³é”®åˆ—æœªè¯†åˆ«ï¼š", {
            "city": col_city,
            "region": col_region,
            "metric_name": col_metric_name,
            "metric_value": col_metric_value,
        })
        print("ğŸ§­ åˆ—åæ ·ä¾‹: ", ", ".join(map(str, list(df.columns)[:12])), "...")
        return 2

    # Build date
    date_series = build_date(df, col_year, col_month, col_day, col_full)
    df = df.copy()
    df["__date__"] = date_series
    if df["__date__"].isna().all():
        print("âŒ æ— æ³•æ„å»ºæœ‰æ•ˆæ—¥æœŸåˆ—ï¼ˆç¼ºå°‘æœˆæˆ–å®Œæ•´æ—¶é—´åˆ—ï¼‰ï¼Œè¯·æ£€æŸ¥åŸå§‹æ•°æ®åˆ—ã€‚")
        return 3

    # Pivot to wide format
    wide = pivot_metrics(df, col_city, col_region, "__date__", col_metric_name, col_metric_value)
    print(f"ğŸ” è½¬ç½®åç»´åº¦: {wide.shape[0]} è¡Œ Ã— {wide.shape[1]} åˆ—")
    os.makedirs(OUT_DIR, exist_ok=True)

    # Filter by date range
    start_d = pd.to_datetime(start).date()
    end_d = pd.to_datetime(end).date()
    mask = (wide["__date__"].notna()) & (wide["__date__"] >= start_d) & (wide["__date__"] <= end_d)
    sel = wide.loc[mask].copy()
    print(f"ğŸ“† è¿‡æ»¤åŒºé—´: [{start} ~ {end}]ï¼ŒåŒ¹é…è¡Œæ•°: {sel.shape[0]}")

    # Per-city summary: ä¸‹å‘é—¨åº—æ•°ä½¿ç”¨ maxï¼Œçº¿ç´¢è¯†åˆ«æ•°ä½¿ç”¨ sum
    city_sum = sel.groupby([col_city, col_region], as_index=False).agg({
        "ä¸‹å‘é—¨åº—æ•°": "max",
        "çº¿ç´¢è¯†åˆ«æ•°": "sum",
    })

    # åˆå¹¶å¤„ç†ï¼šå°†â€œä¸Šæµ·å¸‚â€åŒåŸä¸åŒåŒºåŸŸçš„è®°å½•åˆå¹¶ä¸ºå•è¡Œ
    # åˆå¹¶é€»è¾‘ï¼š
    # - çº¿ç´¢è¯†åˆ«æ•°ï¼šå¯¹åŒåŸçš„åŒºåŸŸè¡Œæ±‚å’Œ
    # - ä¸‹å‘é—¨åº—æ•°ï¼šå¯¹åŒåŸçš„åŒºåŸŸè¡Œæ±‚å’Œï¼ˆä¿æŒä¸æ€»è®¡ä¸€è‡´ï¼Œæ€»è®¡æŒ‰åŸå¸‚è¡Œç›¸åŠ ï¼‰
    #   æ³¨ï¼šè‹¥éœ€æ”¹ä¸ºåŒåŸâ€œmaxâ€å¯å°†ä¸‹æ–¹ sum æ”¹ä¸º maxï¼Œä½†è¿™ä¼šæ”¹å˜æ€»è®¡å£å¾„
    def merge_city_rows(df: pd.DataFrame, city_name: str) -> pd.DataFrame:
        rows = df[df[col_city] == city_name]
        if len(rows) <= 1:
            return df
        merged_assign = int(pd.to_numeric(rows["ä¸‹å‘é—¨åº—æ•°"], errors="coerce").fillna(0).sum())
        merged_identify = int(pd.to_numeric(rows["çº¿ç´¢è¯†åˆ«æ•°"], errors="coerce").fillna(0).sum())
        # é€‰æ‹©é¦–ä¸ªéç©ºåŒºåŸŸä½œä¸ºå±•ç¤ºï¼ˆä¹Ÿå¯å›ºå®šä¸ºâ€œåˆå¹¶â€æˆ–â€œä¸Šæµ·åŒºâ€ï¼‰
        region_value = (
            rows[col_region].dropna().iloc[0] if not rows[col_region].dropna().empty else ""
        )
        new_row = {
            col_city: city_name,
            col_region: region_value,
            "ä¸‹å‘é—¨åº—æ•°": merged_assign,
            "çº¿ç´¢è¯†åˆ«æ•°": merged_identify,
        }
        df = df[df[col_city] != city_name]
        df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)
        return df

    city_sum = merge_city_rows(city_sum, "ä¸Šæµ·å¸‚")
    # Compute totals: ä¸‹å‘é—¨åº—æ•°ä¸ºå„åŸå¸‚æœ€å¤§å€¼ä¹‹å’Œï¼›çº¿ç´¢è¯†åˆ«æ•°ä¸ºåŒºé—´å†…æ€»å’Œ
    total_assign = int(city_sum["ä¸‹å‘é—¨åº—æ•°"].sum())
    total_identify = int(sel["çº¿ç´¢è¯†åˆ«æ•°"].sum())
    print(f"âœ… æ€»è®¡ï¼ˆ{start}~{end}ï¼‰ï¼šä¸‹å‘é—¨åº—æ•°={total_assign}ï¼Œçº¿ç´¢è¯†åˆ«æ•°={total_identify}")

    # Daily leads summary within range: æ¯å¤©çº¿ç´¢è¯†åˆ«æ•°ï¼ˆå…¨åŸå¸‚åˆè®¡ï¼‰
    daily_leads = sel.groupby("__date__", as_index=False)["çº¿ç´¢è¯†åˆ«æ•°"].sum()
    # Show a preview of first 7 days
    preview_days = min(7, len(daily_leads))
    if preview_days > 0:
        print("ğŸ“… åŒºé—´å†…æ¯æ—¥çº¿ç´¢è¯†åˆ«æ•°é¢„è§ˆï¼š")
        for _, row in daily_leads.sort_values("__date__").head(preview_days).iterrows():
            print(f"- {row['__date__']}: çº¿ç´¢è¯†åˆ«æ•°={int(row['çº¿ç´¢è¯†åˆ«æ•°'])}")

    # Build a single Markdown report
    def df_to_md(df: pd.DataFrame, columns: list, headers: list) -> str:
        out = ["|" + "|".join(headers) + "|", "|" + "|".join(["---"] * len(headers)) + "|"]
        for _, r in df[columns].iterrows():
            row = [str(r[c]) for c in columns]
            out.append("|" + "|".join(row) + "|")
        return "\n".join(out)

    report_name = f"leads_assign_summary_{start}_to_{end}.md"
    report_path = os.path.join(OUT_DIR, report_name)

    # Sort city summary by çº¿ç´¢è¯†åˆ«æ•° desc
    city_sum_sorted = city_sum.sort_values("çº¿ç´¢è¯†åˆ«æ•°", ascending=False).copy()
    # Ensure integer formatting
    city_sum_sorted["ä¸‹å‘é—¨åº—æ•°"] = city_sum_sorted["ä¸‹å‘é—¨åº—æ•°"].astype(int)
    city_sum_sorted["çº¿ç´¢è¯†åˆ«æ•°"] = city_sum_sorted["çº¿ç´¢è¯†åˆ«æ•°"].astype(int)

    daily_sorted = daily_leads.sort_values("__date__").copy()
    daily_sorted["çº¿ç´¢è¯†åˆ«æ•°"] = daily_sorted["çº¿ç´¢è¯†åˆ«æ•°"].astype(int)

    lines = []
    lines.append(f"# çº¿ç´¢ä¸é—¨åº—ä¸‹å‘æ±‡æ€»æŠ¥å‘Š\n")
    lines.append(f"- æºæ–‡ä»¶: `{input_path}`")
    lines.append(f"- æ—¶é—´åŒºé—´: `{start}` ~ `{end}`\n")
    lines.append("## åŒºé—´æ€»è®¡")
    lines.append(f"- ä¸‹å‘é—¨åº—æ•°ï¼ˆæŒ‰åŸå–åŒºé—´å†…æ—¥maxåç›¸åŠ ï¼‰: `{total_assign}`")
    lines.append(f"- çº¿ç´¢è¯†åˆ«æ•°ï¼ˆåŒºé—´å†…åˆè®¡ï¼‰: `{total_identify}`\n")

    lines.append("## åˆ†åŸå¸‚æ±‡æ€»ï¼ˆæŒ‰çº¿ç´¢è¯†åˆ«æ•°é™åºï¼‰")
    lines.append(df_to_md(
        city_sum_sorted,
        [col_city, col_region, "ä¸‹å‘é—¨åº—æ•°", "çº¿ç´¢è¯†åˆ«æ•°"],
        ["åŸå¸‚", "åŒºåŸŸ", "ä¸‹å‘é—¨åº—æ•°(max)", "çº¿ç´¢è¯†åˆ«æ•°(sum)"]
    ))
    lines.append("")

    lines.append("## æ¯æ—¥çº¿ç´¢è¯†åˆ«æ•°ï¼ˆå…¨åŸå¸‚åˆè®¡ï¼‰")
    lines.append(df_to_md(
        daily_sorted,
        ["__date__", "çº¿ç´¢è¯†åˆ«æ•°"],
        ["æ—¥æœŸ", "çº¿ç´¢è¯†åˆ«æ•°(sum)"]
    ))
    lines.append("")

    with open(report_path, "w", encoding="utf-8") as f:
        f.write("\n".join(lines))
    print(f"ğŸ“ å·²ç”ŸæˆMarkdownæŠ¥å‘Š: {report_path}")

    # Show top 10 cities by çº¿ç´¢è¯†åˆ«æ•°
    top10 = city_sum.sort_values("çº¿ç´¢è¯†åˆ«æ•°", ascending=False).head(10)
    print("ğŸ™ï¸ Top10 åŸå¸‚ï¼ˆæŒ‰çº¿ç´¢è¯†åˆ«æ•°ï¼‰ï¼š")
    for _, row in top10.iterrows():
        print(f"- {row[col_city]}ï¼ˆ{row[col_region]}ï¼‰ï¼šçº¿ç´¢è¯†åˆ«æ•°={int(row['çº¿ç´¢è¯†åˆ«æ•°'])}ï¼Œä¸‹å‘é—¨åº—æ•°={int(row['ä¸‹å‘é—¨åº—æ•°'])}")

    return 0


if __name__ == "__main__":
    raise SystemExit(main())