#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Order å®Œæ•´æ•°æ®å¤„ç†è„šæœ¬

è¯¥è„šæœ¬ç”¨äºå¤„ç† Order_å®Œæ•´æ•°æ®_data.csv å’Œ Order_å®Œæ•´æ•°æ®_data_2024.csv æ–‡ä»¶
å°†å…¶åˆå¹¶ã€å»é‡å¹¶è½¬æ¢ä¸ºä¼˜åŒ–çš„ Parquet æ ¼å¼

è¾“å…¥æ–‡ä»¶: 
- original/Order_å®Œæ•´æ•°æ®_data.csv
- original/Order_å®Œæ•´æ•°æ®_data_2024.csv
è¾“å‡ºæ–‡ä»¶: formatted/order_full_data.parquet
"""

import pandas as pd
import numpy as np
import os
from pathlib import Path
from datetime import datetime

# è®¾ç½®åŸºç¡€è·¯å¾„
BASE_DIR = Path("/Users/zihao_/Documents/coding/dataset")
ORIGINAL_DIR = BASE_DIR / "original"
FORMATTED_DIR = BASE_DIR / "formatted"
OUTPUT_FILE = FORMATTED_DIR / "order_full_data.parquet"

def read_csv_smart(file_path: Path) -> pd.DataFrame:
    """
    æ™ºèƒ½è¯»å– CSV æ–‡ä»¶ï¼Œå°è¯•å¤šç§ç¼–ç å’Œåˆ†éš”ç¬¦
    """
    if not file_path.exists():
        print(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return pd.DataFrame()

    print(f"ğŸ“– æ­£åœ¨è¯»å–: {file_path.name} ...")
    
    # å¸¸è§ç¼–ç å’Œåˆ†éš”ç¬¦ç»„åˆ
    encodings = ["utf-16", "utf-8", "utf-8-sig", "gb18030", "gbk"]
    separators = ["\t", ","]
    
    for enc in encodings:
        for sep in separators:
            try:
                df = pd.read_csv(file_path, encoding=enc, sep=sep)
                
                # ç®€å•éªŒè¯è¯»å–æ˜¯å¦æˆåŠŸï¼šå¦‚æœåˆ—æ•°åªæœ‰1ä¸”åŒ…å«åˆ†éš”ç¬¦ï¼Œè¯´æ˜åˆ†éš”ç¬¦ä¸å¯¹
                if df.shape[1] == 1 and sep in str(df.columns[0]):
                    continue
                
                # å¦‚æœåˆ—æ•°å¤§äº1ï¼Œé€šå¸¸è¯´æ˜è¯»å–æ­£ç¡®
                if df.shape[1] > 1:
                    print(f"âœ… è¯»å–æˆåŠŸ (ç¼–ç : {enc}, åˆ†éš”ç¬¦: '{sep if sep != '\t' else '\\t'}') - å½¢çŠ¶: {df.shape}")
                    return df
            except Exception:
                continue
                
    # å¦‚æœéƒ½å¤±è´¥äº†ï¼Œå°è¯•é»˜è®¤è¯»å–
    try:
        print("âš ï¸ å°è¯•é»˜è®¤å‚æ•°è¯»å–...")
        return pd.read_csv(file_path)
    except Exception as e:
        print(f"âŒ è¯»å–å¤±è´¥: {e}")
        return pd.DataFrame()

def clean_column_names(df: pd.DataFrame) -> pd.DataFrame:
    """
    æ¸…ç†åˆ—åï¼šå»é™¤ç©ºç™½å­—ç¬¦ï¼Œç»Ÿä¸€å‘½åé£æ ¼
    """
    # å»é™¤å‰åç©ºæ ¼
    df.columns = df.columns.str.strip()
    
    # é¢„å¤„ç†ï¼šç»Ÿä¸€å°† 'xxx_å¹´/æœˆ/æ—¥' æ ¼å¼è½¬æ¢ä¸º 'xxx å¹´/æœˆ/æ—¥'ï¼Œä»¥åŒ¹é…ä¸‹æ–¹çš„æ˜ å°„è¡¨
    # è¿™æ ·å¯ä»¥å…¼å®¹ä¸‹åˆ’çº¿å’Œç©ºæ ¼ä¸¤ç§åˆ†éš”ç¬¦
    df.columns = df.columns.str.replace('_å¹´/æœˆ/æ—¥', ' å¹´/æœˆ/æ—¥', regex=False)

    # é‡å‘½åæ˜ å°„è¡¨ï¼ˆæ ¹æ®ä¹‹å‰çš„åˆ†ææŠ¥å‘Šï¼‰
    rename_map = {
        'first_touch_time å¹´/æœˆ/æ—¥': 'first_touch_time',
        'delivery_date å¹´/æœˆ/æ—¥': 'delivery_date',
        'deposit_payment_time å¹´/æœˆ/æ—¥': 'deposit_payment_time',
        'deposit_refund_time å¹´/æœˆ/æ—¥': 'deposit_refund_time',
        'first_test_drive_time å¹´/æœˆ/æ—¥': 'first_test_drive_time',
        'intention_payment_time å¹´/æœˆ/æ—¥': 'intention_payment_time',
        'intention_refund_time å¹´/æœˆ/æ—¥': 'intention_refund_time',
        'invoice_upload_time å¹´/æœˆ/æ—¥': 'invoice_upload_time',
        'lock_time å¹´/æœˆ/æ—¥': 'lock_time',
        'order_create_time å¹´/æœˆ/æ—¥': 'order_create_date', # åŒºåˆ† order_create_time
        'store_create_date å¹´/æœˆ/æ—¥': 'store_create_date',
        'approve_refund_time å¹´/æœˆ/æ—¥': 'approve_refund_time',
        'apply_refund_time å¹´/æœˆ/æ—¥': 'apply_refund_time',
        'Td CountD': 'td_countd',
        'Drive Series Cn': 'drive_series_cn',
        'Main Lead Id': 'main_lead_id',
    }
    
    # åº”ç”¨é‡å‘½å
    df = df.rename(columns=rename_map)
    
    # å°†å‰©ä½™åˆ—åè½¬æ¢ä¸ºä¸‹åˆ’çº¿é£æ ¼ï¼ˆå¦‚æœå·²ç»æ˜¯è‹±æ–‡ï¼‰
    # è¿™é‡Œç®€å•å¤„ç†ï¼Œåªæ›¿æ¢ç©ºæ ¼
    df.columns = df.columns.str.replace(' ', '_')
    
    return df

def convert_types(df: pd.DataFrame) -> pd.DataFrame:
    """
    è½¬æ¢æ•°æ®ç±»å‹
    """
    print("ğŸ”„ å¼€å§‹ç±»å‹è½¬æ¢...")
    
    # 1. æ—¥æœŸåˆ—è½¬æ¢
    date_cols = [
        'first_touch_time', 'delivery_date', 'deposit_payment_time', 
        'deposit_refund_time', 'first_test_drive_time', 'intention_payment_time', 
        'intention_refund_time', 'invoice_upload_time', 'lock_time', 
        'order_create_date', 'store_create_date', 'order_create_time',
        'approve_refund_time', 'apply_refund_time'
    ]
    
    for col in date_cols:
        if col in df.columns:
            # å¤„ç†ä¸­æ–‡æ—¥æœŸæ ¼å¼ (YYYYå¹´MMæœˆDDæ—¥)
            # å…ˆå°† series è½¬ä¸º string
            s = df[col].astype(str)
            # æ›¿æ¢å¹´æœˆæ—¥
            s = s.str.replace('å¹´', '-', regex=False).str.replace('æœˆ', '-', regex=False).str.replace('æ—¥', '', regex=False)
            # å¤„ç†å¯èƒ½çš„ 'nan' å­—ç¬¦ä¸²
            s = s.replace({'nan': None, 'None': None, '': None})
            
            df[col] = pd.to_datetime(s, errors='coerce')
            print(f"   - æ—¥æœŸåˆ—è½¬æ¢: {col}")

    # 2. æ•°å€¼åˆ—è½¬æ¢
    numeric_cols = ['age', 'invoice_amount', 'td_countd']
    for col in numeric_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
            print(f"   - æ•°å€¼åˆ—è½¬æ¢: {col}")

    # 3. åˆ†ç±»åˆ—è½¬æ¢ (ä¼˜åŒ–å­˜å‚¨)
    cat_cols = [
        'product_name', 'final_payment_way', 'finance_product', 
        'first_middle_channel_name', 'gender', 'is_hold', 'is_staff',
        'license_city', 'license_city_level', 'license_province',
        'order_type', 'series', 'store_city', 'belong_intent_series',
        'drive_series_cn'
    ]
    
    for col in cat_cols:
        if col in df.columns:
            # å¦‚æœå”¯ä¸€å€¼æ•°é‡è¾ƒå°‘ï¼Œè½¬ä¸º category
            if df[col].nunique() < df.shape[0] * 0.5:
                df[col] = df[col].astype('category')
                print(f"   - åˆ†ç±»åˆ—è½¬æ¢: {col}")
            else:
                df[col] = df[col].astype('string')

    # order_number åº”è¯¥æ˜¯å­—ç¬¦ä¸²
    if 'order_number' in df.columns:
        df['order_number'] = df['order_number'].astype('string')

    return df

def main():
    # 1. æŸ¥æ‰¾æœ€æ–°çš„æ•°æ®æ–‡ä»¶
    csv_files = sorted(list(ORIGINAL_DIR.glob("Order_å®Œæ•´æ•°æ®*.csv")), key=lambda x: x.stat().st_mtime, reverse=True)
    
    if not csv_files:
        print(f"âŒ æœªåœ¨ {ORIGINAL_DIR} æ‰¾åˆ°ä»»ä½• 'Order_å®Œæ•´æ•°æ®*.csv' æ–‡ä»¶")
        return

    latest_file = csv_files[0]
    print(f"ğŸ” å‘ç°æœ€æ–°æ•°æ®æ–‡ä»¶: {latest_file.name}")
    
    # 2. è¯»å–æ–°æ•°æ®
    df_new = read_csv_smart(latest_file)
    if df_new.empty:
        print("âŒ è¯»å–æ–°æ•°æ®å¤±è´¥ï¼Œé€€å‡ºã€‚")
        return
        
    # 3. æ¸…ç†åˆ—åå’Œè½¬æ¢ç±»å‹ï¼ˆåœ¨æ–°æ•°æ®ä¸Šè¿›è¡Œï¼‰
    df_new = clean_column_names(df_new)
    df_new = convert_types(df_new)
    
    print(f"âœ… æ–°æ•°æ®å¤„ç†å®Œæˆ: {df_new.shape[0]} è¡Œ")

    # 4. å¢é‡æ›´æ–°é€»è¾‘
    if OUTPUT_FILE.exists():
        print(f"ğŸ“š å‘ç°ç°æœ‰ Parquet æ–‡ä»¶: {OUTPUT_FILE}")
        try:
            df_existing = pd.read_parquet(OUTPUT_FILE)
            print(f"   ç°æœ‰æ•°æ®: {df_existing.shape[0]} è¡Œ")

            # ä¿®å¤ï¼šé‡å‘½åæ—§æ•°æ®ä¸­çš„æœªæ¸…æ´—åˆ—å (é˜²æ­¢ duplicate columns)
            legacy_map = {
                'approve_refund_time_å¹´/æœˆ/æ—¥': 'approve_refund_time',
                'apply_refund_time_å¹´/æœˆ/æ—¥': 'apply_refund_time',
                'approve_refund_time å¹´/æœˆ/æ—¥': 'approve_refund_time', # å¢åŠ ç©ºæ ¼ç‰ˆæœ¬ä»¥é˜²ä¸‡ä¸€
                'apply_refund_time å¹´/æœˆ/æ—¥': 'apply_refund_time'
            }
            
            for old_col, new_col in legacy_map.items():
                if old_col in df_existing.columns:
                    print(f"   ğŸ§¹ å¤„ç†æ—§æ•°æ®åˆ—: {old_col} -> {new_col}")
                    
                    # 1. å…ˆè½¬æ¢ç±»å‹ (å¦‚æœæ˜¯å­—ç¬¦ä¸²)
                    if df_existing[old_col].dtype == 'object':
                         try:
                             s = df_existing[old_col].astype(str)
                             s = s.str.replace('å¹´', '-', regex=False).str.replace('æœˆ', '-', regex=False).str.replace('æ—¥', '', regex=False)
                             s = s.replace({'nan': None, 'None': None, '': None})
                             df_existing[old_col] = pd.to_datetime(s, errors='coerce')
                         except Exception as e:
                             print(f"      âš ï¸ è½¬æ¢å¤±è´¥: {e}")

                    # 2. åˆå¹¶æˆ–é‡å‘½å
                    if new_col in df_existing.columns:
                        # å¦‚æœç›®æ ‡åˆ—å·²å­˜åœ¨ï¼Œåˆå¹¶ (ä¼˜å…ˆä¿ç•™ç›®æ ‡åˆ—çš„å€¼ï¼Œå¡«å…… NaNs)
                        df_existing[new_col] = df_existing[new_col].combine_first(df_existing[old_col])
                        df_existing = df_existing.drop(columns=[old_col])
                    else:
                        # ç›´æ¥é‡å‘½å
                        df_existing = df_existing.rename(columns={old_col: new_col})

            # ä¿®å¤ï¼šç§»é™¤å†—ä½™çš„ order_create_time åˆ—ï¼ˆå¦‚æœå­˜åœ¨ï¼Œä¸”ä¸ order_create_date é‡å¤æˆ–æ–°æ•°æ®æ— æ­¤åˆ—ï¼‰
            # if 'order_create_time' in df_existing.columns:
            #    print("   ğŸ§¹ æ¸…ç†å†—ä½™åˆ— 'order_create_time' ä»¥ä¿æŒç»“æ„ä¸€è‡´...")
            #    df_existing = df_existing.drop(columns=['order_create_time'])
            
            # ç¡®ä¿åˆ—ç»“æ„ä¸€è‡´
            common_cols = list(set(df_existing.columns) & set(df_new.columns))
            new_only = set(df_new.columns) - set(df_existing.columns)
            existing_only = set(df_existing.columns) - set(df_new.columns)
            
            if new_only or existing_only:
                print(f"âš ï¸ åˆ—ç»“æ„ä¸ä¸€è‡´:")
                if new_only: print(f"   æ–°æ•°æ®ç‹¬æœ‰: {new_only}")
                if existing_only: print(f"   æ—§æ•°æ®ç‹¬æœ‰: {existing_only}")
                
                # å¯¹é½åˆ—
                all_cols = list(set(df_existing.columns) | set(df_new.columns))
                df_existing = df_existing.reindex(columns=all_cols)
                df_new = df_new.reindex(columns=all_cols)
            
            # æ™ºèƒ½åˆå¹¶
            if 'order_number' in df_new.columns and 'order_number' in df_existing.columns:
                print(f"ğŸ”„ æ‰§è¡Œæ™ºèƒ½å¢é‡åˆå¹¶...")
                
                # è½¬æ¢ä¸ºé›†åˆè¿›è¡Œå¿«é€ŸæŸ¥æ‰¾
                existing_orders = set(df_existing['order_number'].dropna())
                new_orders = set(df_new['order_number'].dropna())
                
                truly_new_orders = new_orders - existing_orders
                updated_orders = new_orders & existing_orders
                
                print(f"   æ–°å¢è®¢å•: {len(truly_new_orders)}")
                print(f"   æ›´æ–°è®¢å•: {len(updated_orders)}")
                
                # 1. ä¿ç•™æ—§æ•°æ®ä¸­ä¸åœ¨æ–°æ•°æ®é‡Œçš„ï¼ˆæœªæ›´æ–°çš„å†å²æ•°æ®ï¼‰
                # æ³¨æ„ï¼šè¿™é‡Œå‡è®¾æ–°æ–‡ä»¶åªæ˜¯å¢é‡æˆ–éƒ¨åˆ†å¿«ç…§ã€‚å¦‚æœæ˜¯å…¨é‡å¿«ç…§ï¼Œé€»è¾‘å¯èƒ½ä¸åŒã€‚
                # ä½†æ ¹æ®ç”¨æˆ·æè¿°ï¼Œä¼¼ä¹æ˜¯å¸Œæœ›ä¿ç•™å†å²ç´¯ç§¯ã€‚
                # å¦‚æœæ–°æ–‡ä»¶åŒ…å«å·²æœ‰çš„è®¢å•ï¼Œé€šå¸¸æˆ‘ä»¬è®¤ä¸ºæ–°æ–‡ä»¶çš„æ•°æ®æ›´æ–°ã€‚
                
                # ç§»é™¤æ—§æ•°æ®ä¸­å°†è¢«æ›´æ–°çš„è®¢å•
                df_final = df_existing[~df_existing['order_number'].isin(updated_orders)].copy()
                
                # æ·»åŠ æ–°æ•°æ®ï¼ˆåŒ…å«çœŸæ­£çš„æ–°å¢å’Œæ›´æ–°çš„è®¢å•ï¼‰
                # è¿™é‡Œå‡è®¾æ–°æ–‡ä»¶é‡Œçš„è®°å½•å°±æ˜¯æœ€æ–°çš„çŠ¶æ€
                df_final = pd.concat([df_final, df_new], ignore_index=True)
                
            else:
                print("âš ï¸ æœªæ‰¾åˆ° order_number åˆ—ï¼Œæ‰§è¡Œè¿½åŠ åˆå¹¶...")
                df_final = pd.concat([df_existing, df_new], ignore_index=True)
                
        except Exception as e:
            print(f"âŒ è¯»å–ç°æœ‰ Parquet æ–‡ä»¶å¤±è´¥: {e}")
            print("   å°†ä»…ä½¿ç”¨æ–°æ•°æ®ã€‚")
            df_final = df_new
    else:
        print("ğŸ“ æœªå‘ç°ç°æœ‰ Parquet æ–‡ä»¶ï¼Œåˆ›å»ºæ–°æ–‡ä»¶...")
        df_final = df_new

    # 5. æœ€ç»ˆå»é‡ï¼ˆä»¥é˜²ä¸‡ä¸€ï¼‰
    if 'order_number' in df_final.columns:
        print(f"âœ‚ï¸  æ‰§è¡Œæœ€ç»ˆå»é‡...")
        before_count = len(df_final)
        # keep='last' ç¡®ä¿ä¿ç•™æœ€ååŠ å…¥çš„è®°å½•ï¼ˆå³æœ€æ–°çš„ï¼‰
        df_final = df_final.drop_duplicates(subset=['order_number'], keep='last')
        after_count = len(df_final)
        print(f"   å»é‡å‰: {before_count}, å»é‡å: {after_count}, ç§»é™¤: {before_count - after_count}")

    # 6. ä¿å­˜
    if not FORMATTED_DIR.exists():
        FORMATTED_DIR.mkdir(parents=True)
    
    print(f"ğŸ’¾ ä¿å­˜åˆ°: {OUTPUT_FILE} ...")
    df_final.to_parquet(OUTPUT_FILE, index=False)
    
    # éªŒè¯
    if OUTPUT_FILE.exists():
        size_mb = OUTPUT_FILE.stat().st_size / (1024 * 1024)
        print(f"âœ… ä¿å­˜æˆåŠŸ! æ–‡ä»¶å¤§å°: {size_mb:.2f} MB")
        print(f"   æœ€ç»ˆè¡Œæ•°: {df_final.shape[0]}")
    else:
        print("âŒ ä¿å­˜å¤±è´¥")

if __name__ == "__main__":
    main()
