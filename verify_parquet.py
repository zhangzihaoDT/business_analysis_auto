import pandas as pd
import pyarrow.parquet as pq
import os

def verify_parquet_file(parquet_path):
    """
    éªŒè¯Parquetæ–‡ä»¶çš„å†…å®¹å’Œç»“æ„
    """
    print(f"ğŸ” éªŒè¯Parquetæ–‡ä»¶: {parquet_path}")
    print("=" * 50)
    
    try:
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(parquet_path):
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {parquet_path}")
            return False
        
        # è·å–æ–‡ä»¶å¤§å°
        file_size = os.path.getsize(parquet_path) / (1024 * 1024)  # MB
        print(f"ğŸ“ æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
        
        # ä½¿ç”¨pyarrowè¯»å–å…ƒæ•°æ®
        parquet_file = pq.ParquetFile(parquet_path)
        print(f"ğŸ“Š è¡Œæ•°: {parquet_file.metadata.num_rows:,}")
        print(f"ğŸ“‹ åˆ—æ•°: {parquet_file.metadata.num_columns}")
        
        # æ˜¾ç¤ºschema
        print("\nğŸ“‹ æ•°æ®ç»“æ„:")
        schema = parquet_file.schema.to_arrow_schema()
        for i, field in enumerate(schema):
            print(f"  {i+1:2d}. {field.name}: {field.type}")
        
        # è¯»å–å‰å‡ è¡Œæ•°æ®è¿›è¡ŒéªŒè¯ï¼ˆåªè¯»å–å‰10000è¡Œä»¥èŠ‚çœå†…å­˜ï¼‰
        print("\nğŸ” æ•°æ®é¢„è§ˆ (å‰5è¡Œ):")
        # ä½¿ç”¨pyarrowè¯»å–éƒ¨åˆ†æ•°æ®
        table = pq.read_table(parquet_path, columns=None)
        df_sample = table.slice(0, 10000).to_pandas()  # åªè¯»å–å‰10000è¡Œ
        print(df_sample.head(5).to_string())
        
        # æ£€æŸ¥æ•°æ®ç±»å‹
        print("\nğŸ“Š æ•°æ®ç±»å‹:")
        for col, dtype in df_sample.dtypes.items():
            print(f"  {col}: {dtype}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç¼ºå¤±å€¼ï¼ˆæ£€æŸ¥å‰1000è¡Œï¼‰
        print("\nğŸ” ç¼ºå¤±å€¼æ£€æŸ¥ (å‰1000è¡Œ):")
        df_subset = df_sample.head(1000)
        missing_counts = df_subset.isnull().sum()
        for col, missing in missing_counts.items():
            if missing > 0:
                print(f"  {col}: {missing} ä¸ªç¼ºå¤±å€¼")
        
        if missing_counts.sum() == 0:
            print("  âœ… å‰1000è¡Œæ— ç¼ºå¤±å€¼")
        
        # æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡ä¿¡æ¯
        print("\nğŸ“ˆ æ•°å€¼åˆ—ç»Ÿè®¡ä¿¡æ¯:")
        numeric_cols = df_sample.select_dtypes(include=['int64', 'float64']).columns
        if len(numeric_cols) > 0:
            print(df_sample[numeric_cols].describe().to_string())
        else:
            print("  æ— æ•°å€¼åˆ—")
        
        print("\nâœ… Parquetæ–‡ä»¶éªŒè¯å®Œæˆï¼")
        return True
        
    except Exception as e:
        print(f"âŒ éªŒè¯å¤±è´¥: {str(e)}")
        return False

if __name__ == "__main__":
    parquet_file = "/Users/zihao_/Documents/coding/dataset/formatted/æœˆåº¦_ä¸Šé™©é‡_0723_optimized.parquet"
    
    print("ğŸš€ å¼€å§‹éªŒè¯Parquetæ–‡ä»¶...")
    success = verify_parquet_file(parquet_file)
    
    if success:
        print("\nğŸ‰ éªŒè¯æˆåŠŸï¼Parquetæ–‡ä»¶æ ¼å¼æ­£ç¡®ã€‚")
    else:
        print("\nâŒ éªŒè¯å¤±è´¥ï¼")
        exit(1)