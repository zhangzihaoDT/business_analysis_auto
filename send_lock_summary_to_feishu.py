import os
import argparse
import requests
import pandas as pd
from pathlib import Path
from dotenv import load_dotenv
import time

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv()

def parse_markdown_table(table_text):
    """
    è§£æ Markdown è¡¨æ ¼ä¸º DataFrame
    """
    try:
        lines = table_text.strip().split('\n')
        valid_lines = []
        for l in lines:
            l = l.strip()
            if not l: continue
            # å¿½ç•¥å¼•ç”¨å—å’Œæ— ç®¡é“ç¬¦çš„è¡Œ
            if l.startswith('>') or '|' not in l: continue
            
            # è¿‡æ»¤æ‰åˆ†éš”è¡Œ (e.g. |---|---|)
            # åªæœ‰ | - : ç©ºæ ¼ çš„è¡Œè¢«è§†ä¸ºåˆ†éš”è¡Œ
            # æ³¨æ„ï¼šæ•°æ®è¡Œå¯èƒ½åŒ…å«è¿™äº›å­—ç¬¦ï¼Œä½†é€šå¸¸è¿˜æœ‰å…¶ä»–å­—ç¬¦
            if not set(l) <= {'|', '-', ':', ' '}:
                valid_lines.append(l)
        
        if not valid_lines:
            return pd.DataFrame()
        
        # æ‰‹åŠ¨è§£æï¼Œæ¯” read_csv æ›´ç¨³å¥
        rows = []
        for l in valid_lines:
            # æŒ‰ | åˆ†å‰²
            parts = l.split('|')
            # ç§»é™¤é¦–å°¾å¯èƒ½çš„ç©ºå­—ç¬¦ä¸² (Markdown è¡¨æ ¼é€šå¸¸ä»¥ | å¼€å§‹å’Œç»“æŸ)
            if len(parts) > 0 and parts[0].strip() == '':
                parts.pop(0)
            if len(parts) > 0 and parts[-1].strip() == '':
                parts.pop(-1)
            # å»é™¤å•å…ƒæ ¼ç©ºæ ¼
            rows.append([p.strip() for p in parts])
            
        if not rows:
            return pd.DataFrame()
            
        header = rows[0]
        data = rows[1:]
        
        # å¤„ç†åˆ—æ•°ä¸ä¸€è‡´çš„æƒ…å†µ (ä»¥è¡¨å¤´ä¸ºå‡†)
        expected_cols = len(header)
        cleaned_data = []
        for r in data:
            if len(r) == expected_cols:
                cleaned_data.append(r)
            elif len(r) < expected_cols:
                # è¡¥å…¨
                cleaned_data.append(r + [''] * (expected_cols - len(r)))
            else:
                # æˆªæ–­
                cleaned_data.append(r[:expected_cols])
                
        df = pd.DataFrame(cleaned_data, columns=header)
        return df
    except Exception as e:
        print(f"è¡¨æ ¼è§£æå¤±è´¥: {e}")
        return pd.DataFrame()

def render_df_as_columns(df):
    """
    å°† DataFrame æ¸²æŸ“ä¸ºé£ä¹¦ ColumnSet ç»“æ„
    """
    if df.empty:
        return []
        
    elements = []
    
    # 1. è¡¨å¤´
    header_cols = []
    for col in df.columns:
        header_cols.append({
            "tag": "column",
            "width": "weighted",
            "weight": 1,
            "elements": [{
                "tag": "markdown",
                "content": f"**{col}**"
            }]
        })
    
    elements.append({
        "tag": "column_set",
        "flex_mode": "none",
        "background_style": "grey",
        "columns": header_cols
    })
    
    # 2. æ•°æ®è¡Œ
    # é™åˆ¶è¡Œæ•°ä»¥é˜²æ¶ˆæ¯è¿‡å¤§ (e.g. max 20 rows)
    MAX_ROWS = 20
    for idx, row in df.head(MAX_ROWS).iterrows():
        row_cols = []
        for val in row:
            row_cols.append({
                "tag": "column",
                "width": "weighted",
                "weight": 1,
                "elements": [{
                    "tag": "markdown",
                    "content": str(val)
                }]
            })
        elements.append({
            "tag": "column_set",
            "flex_mode": "none",
            "columns": row_cols
        })
        
    if len(df) > MAX_ROWS:
        elements.append({
             "tag": "div",
             "text": {
                 "tag": "plain_text",
                 "content": f"... (å‰©ä½™ {len(df) - MAX_ROWS} è¡Œå·²çœç•¥)"
             }
        })
        
    return elements

def extract_section(content, header):
    """
    æå–æŒ‡å®šæ ‡é¢˜ä¸‹çš„å†…å®¹
    """
    try:
        parts = content.split(f"## {header}")
        if len(parts) < 2:
            return ""
        # æŸ¥æ‰¾ä¸‹ä¸€ä¸ªæ ‡é¢˜ï¼ˆä»¥ ## å¼€å¤´ï¼‰æˆ–æ–‡ä»¶ç»“æŸ
        section = parts[1].split("\n## ")[0].strip()
        return section
    except Exception:
        return ""

def format_overview(content):
    """
    æ ¼å¼åŒ–æ¦‚è§ˆç»Ÿè®¡
    """
    section = extract_section(content, "æ¦‚è§ˆç»Ÿè®¡")
    if not section:
        return []
    
    df = parse_markdown_table(section)
    if df.empty:
        return []
    
    fields = []
    for _, row in df.iterrows():
        key = str(row.iloc[0])
        val = str(row.iloc[1])
        fields.append({
            "is_short": True,
            "text": {
                "tag": "lark_md",
                "content": f"**{key}**\n{val}"
            }
        })
    return fields

def format_table_section(content, header, title, emoji="ğŸ“Š"):
    """
    å°†è¡¨æ ¼éƒ¨åˆ†æ ¼å¼åŒ–ä¸ºé£ä¹¦ ColumnSetï¼Œä¿æŒå¯¹é½
    """
    section = extract_section(content, header)
    if not section:
        return None
    
    # å°è¯•æå–æ³¨é‡Šï¼ˆå¼•ç”¨å—ï¼‰
    lines = section.split('\n')
    notes = [l.strip('> ').strip() for l in lines if l.strip().startswith('>')]
    note_text = "\n".join(notes)
    
    # è§£æè¡¨æ ¼
    df = parse_markdown_table(section)
    
    if df.empty:
        return None
        
    elements = []
    # æ ‡é¢˜
    elements.append({
        "tag": "div",
        "text": {
            "tag": "lark_md",
            "content": f"**{emoji} {title}**"
        }
    })
    
    # è¡¨æ ¼å†…å®¹ (ColumnSet)
    elements.extend(render_df_as_columns(df))
    
    # æ³¨é‡Šï¼ˆå¦‚æœæœ‰ï¼‰
    if note_text:
        elements.append({
            "tag": "note",
            "elements": [{
                "tag": "plain_text",
                "content": f"æ³¨: {note_text}"
            }]
        })
        
    return elements

def format_age_stats(content):
    """
    æ ¼å¼åŒ–è½¦ä¸»å¹´é¾„ç»Ÿè®¡ï¼ˆåˆ—è¡¨è½¬å­—æ®µï¼‰
    """
    section = extract_section(content, "è½¦ä¸»å¹´é¾„ç»Ÿè®¡")
    if not section:
        return None
        
    lines = [l.strip('- ').strip() for l in section.split('\n') if l.strip().startswith('-')]
    if not lines:
        return None
        
    fields = []
    for line in lines:
        if ':' in line:
            k, v = line.split(':', 1)
            fields.append({
                "is_short": True,
                "text": {
                    "tag": "lark_md",
                    "content": f"**{k.strip()}**\n{v.strip()}"
                }
            })
            
    if not fields:
        return None

    return {
        "tag": "div",
        "fields": fields
    }

def send_report(file_path):
    file_path = Path(file_path)
    if not file_path.exists():
        print(f"é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨ {file_path}")
        return

    content = file_path.read_text(encoding='utf-8')
    
    # æå–åŸºæœ¬ä¿¡æ¯
    time_range = "æœªçŸ¥"
    for line in content.split('\n'):
        if line.strip().startswith("- æ—¶é—´åŒºé—´:"):
            time_range = line.split(":", 1)[1].strip().replace('`', '')
            break
    
    def detect_models(txt):
        candidates = [
            "åˆ†å¹´é¾„æ®µçš„é”å•é‡ä¸å æ¯”ï¼ˆåˆ†è½¦å‹å æ¯”%ï¼‰",
            "åˆ† license_city_level çš„é”å•é‡ï¼ˆåˆ†è½¦å‹å æ¯”%ï¼‰",
            "åˆ† License Province çš„é”å•é‡ï¼ˆåˆ†è½¦å‹å æ¯”%ï¼‰",
            "åˆ† License City çš„é”å•é‡ï¼ˆTop 10 Cities Breakdownï¼‰",
        ]
        for h in candidates:
            s = extract_section(txt, h)
            if not s:
                continue
            df = parse_markdown_table(s)
            if df.empty:
                continue
            cols = list(df.columns)
            if len(cols) >= 2:
                models = cols[1:]
            else:
                models = []
            models = [m.strip() for m in models if m.strip()]
            if models:
                return models
        return []
    
    def detect_sections(txt):
        headers_map = {
            "overview": ["æ¦‚è§ˆç»Ÿè®¡ï¼ˆåˆ†è½¦å‹ï¼‰", "æ¦‚è§ˆç»Ÿè®¡"],
            "deposit": ["å¤§å®šç•™å­˜çš„ Deposit_Payment_Time åˆ†å¸ƒï¼ˆæŒ‰æ—¥ï¼Œåˆ†è½¦å‹ï¼‰", "å¤§å®šç•™å­˜çš„ Deposit_Payment_Time åˆ†å¸ƒï¼ˆæŒ‰æ—¥ï¼‰"],
            "region": ["åŒºåŸŸ x ä¸šåŠ¡å®šä¹‰çŸ©é˜µ", "åŒºåŸŸ x è½¦å‹çŸ©é˜µ"],
            "city_level": ["åˆ† license_city_level çš„é”å•é‡ä¸å æ¯”", "åˆ† license_city_level çš„é”å•é‡ï¼ˆåˆ†è½¦å‹å æ¯”%ï¼‰"],
            "province": ["åˆ† License Province çš„é”å•é‡ä¸å æ¯”", "åˆ† License Province çš„é”å•é‡ï¼ˆåˆ†è½¦å‹å æ¯”%ï¼‰"],
            "city": ["åˆ† License City çš„é”å•é‡ä¸å æ¯”ï¼ˆTop 10ï¼‰", "åˆ† License City çš„é”å•é‡ï¼ˆTop 10 Cities Breakdownï¼‰"],
            "age": ["è½¦ä¸»å¹´é¾„ç»Ÿè®¡", "è½¦ä¸»å¹´é¾„ç»Ÿè®¡ï¼ˆåˆ†è½¦å‹ï¼‰", "åˆ†å¹´é¾„æ®µçš„é”å•é‡ä¸å æ¯”", "åˆ†å¹´é¾„æ®µçš„é”å•é‡ä¸å æ¯”ï¼ˆåˆ†è½¦å‹å æ¯”%ï¼‰"],
            "gender": ["åˆ†æ€§åˆ«çš„é”å•é‡ä¸å æ¯”"],
        }
        included = []
        for key, headers in headers_map.items():
            for h in headers:
                if f"## {h}" in txt:
                    included.append(key)
                    break
        order = ["overview", "deposit", "region", "city_level", "province", "city", "age", "gender"]
        return [k for k in order if k in included]
    
    def build_title(models_list, sections_list):
        cn_map = {
            "overview": "æ¦‚è§ˆ",
            "deposit": "å¤§å®š",
            "region": "åœ°åŸŸ",
            "city_level": "åŸå¸‚çº§åˆ«",
            "province": "çœä»½",
            "city": "åŸå¸‚",
            "age": "å¹´é¾„",
            "gender": "æ€§åˆ«",
        }
        sec_cn = [cn_map.get(s, s) for s in sections_list]
        sec_text = "ã€".join(sec_cn) if sec_cn else "å…¨éƒ¨æ¨¡å—"
        if models_list:
            mod_text = "ã€".join(models_list[:4]) + (" ç­‰" if len(models_list) > 4 else "")
        else:
            mod_text = "å…¨éƒ¨è½¦å‹"
        return f"ğŸ“Š é”å•æ±‡æ€»ï½œæ¨¡å—ï¼š{sec_text}ï½œè½¦å‹ï¼š{mod_text}"
    
    models = detect_models(content)
    sections = detect_sections(content)
    dynamic_title = build_title(models, sections)
    
    # æ„å»ºé£ä¹¦å¡ç‰‡
    webhook = os.getenv("FS_WEBHOOK_URL")
    if not webhook:
        print("é”™è¯¯: æœªæ‰¾åˆ° FS_WEBHOOK_URL ç¯å¢ƒå˜é‡ã€‚")
        return

    card_elements = []

    # --- 1. æ¦‚è§ˆç»Ÿè®¡ (L4-13) ---
    card_elements.append({
        "tag": "div",
        "text": {
            "tag": "lark_md",
            "content": f"ğŸ•’ **ç»Ÿè®¡å‘¨æœŸ**\n{time_range}"
        }
    })
    
    overview_fields = format_overview(content)
    if overview_fields:
        card_elements.append({"tag": "hr"})
        card_elements.append({
            "tag": "div",
            "text": {
                "tag": "lark_md",
                "content": "**ğŸ“ˆ æ ¸å¿ƒæŒ‡æ ‡**"
            }
        })
        card_elements.append({
            "tag": "div",
            "fields": overview_fields
        })

    # --- 2. åœ°åŸŸåˆ†å¸ƒ (L147-183) ---
    card_elements.append({"tag": "hr"})
    card_elements.append({
        "tag": "div",
        "text": {
            "tag": "lark_md",
            "content": "**ğŸ—ºï¸ åœ°åŸŸåˆ†å¸ƒ**"
        }
    })

    # åŸå¸‚çº§åˆ«
    level_elems = format_table_section(content, "åˆ† license_city_level çš„é”å•é‡ä¸å æ¯”", "åŸå¸‚çº§åˆ«", "ğŸ™ï¸")
    if level_elems:
        card_elements.extend(level_elems)

    level_model_elems = format_table_section(content, "åˆ† license_city_level çš„é”å•é‡ï¼ˆåˆ†è½¦å‹å æ¯”%ï¼‰", "åŸå¸‚çº§åˆ«ï¼ˆåˆ†è½¦å‹%ï¼‰", "ğŸš™")
    if level_model_elems:
        card_elements.extend(level_model_elems)

    # Top çœä»½
    # æ³¨æ„ï¼šlock_summary.py ä¸­æ ‡é¢˜ä¸º "åˆ† License Province çš„é”å•é‡ä¸å æ¯”"
    prov_elems = format_table_section(content, "åˆ† License Province çš„é”å•é‡ä¸å æ¯”", "Top çœä»½", "ğŸ›ï¸")
    if prov_elems:
        card_elements.extend(prov_elems)
    
    prov_model_elems = format_table_section(content, "åˆ† License Province çš„é”å•é‡ï¼ˆåˆ†è½¦å‹å æ¯”%ï¼‰", "Top çœä»½ï¼ˆåˆ†è½¦å‹%ï¼‰", "ğŸš™")
    if prov_model_elems:
        card_elements.extend(prov_model_elems)

    # Top åŸå¸‚
    city_elems = format_table_section(content, "åˆ† License City çš„é”å•é‡ä¸å æ¯”ï¼ˆTop 10ï¼‰", "Top 10 åŸå¸‚", "ğŸŒ†")
    if city_elems:
        card_elements.extend(city_elems)
        
    city_model_elems = format_table_section(content, "åˆ† License City çš„é”å•é‡ï¼ˆTop 10 Cities Breakdownï¼‰", "Top 10 åŸå¸‚ï¼ˆåˆ†è½¦å‹ï¼‰", "ğŸš™")
    if city_model_elems:
        card_elements.extend(city_model_elems)

    # --- 3. ç”¨æˆ·ç”»åƒ (L184-208) ---
    card_elements.append({"tag": "hr"})
    card_elements.append({
        "tag": "div",
        "text": {
            "tag": "lark_md",
            "content": "**ğŸ‘¥ ç”¨æˆ·ç”»åƒ**"
        }
    })

    # å¹´é¾„ç»Ÿè®¡ (å‡å€¼/ä¸­ä½æ•°)
    age_stats_elem = format_age_stats(content)
    if age_stats_elem:
        card_elements.append({
            "tag": "div",
            "text": {
                "tag": "lark_md",
                "content": "**ğŸ‚ å¹´é¾„æ¦‚è§ˆ**"
            }
        })
        card_elements.append(age_stats_elem)

    # å¹´é¾„æ®µåˆ†å¸ƒ
    age_dist_elems = format_table_section(content, "åˆ†å¹´é¾„æ®µçš„é”å•é‡ä¸å æ¯”", "å¹´é¾„æ®µåˆ†å¸ƒ", "ğŸ“Š")
    if age_dist_elems:
        card_elements.extend(age_dist_elems)

    age_model_elems = format_table_section(content, "åˆ†å¹´é¾„æ®µçš„é”å•é‡ä¸å æ¯”ï¼ˆåˆ†è½¦å‹å æ¯”%ï¼‰", "å¹´é¾„æ®µåˆ†å¸ƒï¼ˆåˆ†è½¦å‹%ï¼‰", "ğŸš™")
    if age_model_elems:
        card_elements.extend(age_model_elems)

    # æ€§åˆ«åˆ†å¸ƒ
    gender_elems = format_table_section(content, "åˆ†æ€§åˆ«çš„é”å•é‡ä¸å æ¯”", "æ€§åˆ«åˆ†å¸ƒ", "ğŸ‘«")
    if gender_elems:
        card_elements.extend(gender_elems)

    # åº•éƒ¨
    card_elements.append({"tag": "hr"})
    card_elements.append({
        "tag": "note",
        "elements": [
            {
                "tag": "plain_text",
                "content": f"æ•°æ®æ¥æº: {file_path.name}"
            }
        ]
    })

    card_data = {
        "msg_type": "interactive",
        "card": {
            "header": {
                "title": {
                    "tag": "plain_text",
                    "content": dynamic_title
                },
                "template": "blue"
            },
            "elements": card_elements
        }
    }

    def try_send_with_retry(webhook_url, payload, retries=(2, 5, 10)):
        print("æ­£åœ¨å‘é€é£ä¹¦æ¶ˆæ¯...")
        for i, wait_s in enumerate([0] + list(retries)):
            if wait_s > 0:
                print(f"é¢‘ç‡é™åˆ¶æˆ–å¼‚å¸¸ï¼Œ{wait_s}s åé‡è¯•ï¼ˆç¬¬ {i} æ¬¡ï¼‰...")
                time.sleep(wait_s)
            try:
                resp = requests.post(webhook_url, json=payload)
                resp.raise_for_status()
                result = {}
                try:
                    result = resp.json()
                except Exception:
                    pass
                status_ok = (result.get("StatusCode") == 0) or (result.get("code") == 0)
                if status_ok:
                    print(f"âœ… æ¶ˆæ¯æ¨é€æˆåŠŸ")
                    return True
                msg = result.get("msg", "")
                code = result.get("code")
                print(f"âŒ æ¶ˆæ¯æ¨é€å¼‚å¸¸: {result}")
                # 11232: frequency limited
                if code == 11232 or ("frequency limited" in msg.lower()):
                    continue
                # å…¶ä»–é”™è¯¯ä¸é‡è¯•
                break
            except requests.exceptions.RequestException as e:
                print(f"âŒ ç½‘ç»œå¼‚å¸¸: {e}")
                continue
        return False
    
    ok = try_send_with_retry(webhook, card_data)
    if not ok:
        # å…œåº•æ–‡æœ¬æ¶ˆæ¯ï¼ŒåŒ…å«æ ‡é¢˜ä¿¡æ¯
        fallback_text = dynamic_title
        try:
            requests.post(webhook, json={
                "msg_type": "text",
                "content": {"text": fallback_text}
            })
        except requests.exceptions.RequestException as e:
            print(f"âŒ æ–‡æœ¬æ¶ˆæ¯æ¨é€å¤±è´¥: {e}")

def main():
    parser = argparse.ArgumentParser(description="å‘é€é”å•æ±‡æ€»æŠ¥å‘Šåˆ°é£ä¹¦")
    
    group = parser.add_mutually_exclusive_group()
    group.add_argument(
        "--file", 
        help="æŒ‡å®šæŠ¥å‘Šæ–‡ä»¶å (éœ€å®Œæ•´æ–‡ä»¶åï¼Œä¾‹å¦‚: lock_summary_2024-01-01_to_2025-12-21.md)ã€‚è„šæœ¬å°†ä¼˜å…ˆåœ¨ processed/analysis_results/ ç›®å½•ä¸‹æŸ¥æ‰¾ï¼Œä¹Ÿå¯ä»¥æä¾›æ–‡ä»¶è·¯å¾„ã€‚"
    )
    group.add_argument(
        "--latest",
        action="store_true",
        help="è‡ªåŠ¨é€‰æ‹© processed/analysis_results/ ç›®å½•ä¸‹æœ€æ–°çš„ lock_summary_*.md æŠ¥å‘Š"
    )

    args = parser.parse_args()
    
    base_dir = Path("processed/analysis_results")
    default_file = base_dir / "lock_summary_2024-01-01_to_2025-12-21.md"

    if args.latest:
        files = list(base_dir.glob("lock_summary_*.md"))
        if not files:
            print(f"é”™è¯¯: åœ¨ {base_dir} ä¸‹æœªæ‰¾åˆ°ä»»ä½• lock_summary æŠ¥å‘Š")
            return
        file_path = max(files, key=os.path.getmtime)
        print(f"å·²é€‰æ‹©æœ€æ–°æŠ¥å‘Š: {file_path}")
    elif args.file:
        # 1. ä¼˜å…ˆåœ¨é»˜è®¤ç›®å½•ä¸‹æŸ¥æ‰¾æ–‡ä»¶å
        candidate = base_dir / args.file
        if candidate.exists():
            file_path = candidate
        else:
            # 2. æ£€æŸ¥æ˜¯å¦ä¸ºæä¾›çš„ç›´æ¥è·¯å¾„
            candidate = Path(args.file)
            if candidate.exists():
                file_path = candidate
            else:
                print(f"é”™è¯¯: æœªæ‰¾åˆ°æ–‡ä»¶ '{args.file}'")
                print(f"  - å·²å°è¯•ç›®å½•: {base_dir}")
                print(f"  - å·²å°è¯•è·¯å¾„: {Path(args.file).absolute()}")
                return
    else:
        file_path = default_file
        
    send_report(file_path)

if __name__ == "__main__":
    main()
