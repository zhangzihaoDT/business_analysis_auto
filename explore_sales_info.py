#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é”€å”®ä¿¡æ¯æ•°æ®æ¢ç´¢æ€§åˆ†æè„šæœ¬
ç”¨äºåˆ†æ sales_info_data.csv æ–‡ä»¶å¹¶è½¬æ¢ä¸º JSON æ ¼å¼
"""

import pandas as pd
import numpy as np
import json
import os
from pathlib import Path

def explore_sales_info_data():
    """
    æ¢ç´¢æ€§åˆ†æé”€å”®ä¿¡æ¯æ•°æ®
    """
    # å®šä¹‰æ–‡ä»¶è·¯å¾„
    input_file = "/Users/zihao_/Documents/coding/dataset/original/sales_info_data.csv"
    output_dir = "/Users/zihao_/Documents/coding/dataset/formatted"
    output_file = os.path.join(output_dir, "sales_info_data.json")
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(output_dir, exist_ok=True)
    
    print("=" * 60)
    print("é”€å”®ä¿¡æ¯æ•°æ®æ¢ç´¢æ€§åˆ†æ")
    print("=" * 60)
    
    try:
        # è¯»å–CSVæ–‡ä»¶ï¼Œå°è¯•ä¸åŒç¼–ç 
        print(f"\næ­£åœ¨è¯»å–æ–‡ä»¶: {input_file}")
        
        # å°è¯•ä¸åŒçš„ç¼–ç æ–¹å¼
        encodings = ['utf-8', 'gbk', 'gb2312', 'utf-16', 'latin-1']
        df = None
        
        for encoding in encodings:
             try:
                 print(f"å°è¯•ä½¿ç”¨ç¼–ç : {encoding}")
                 # å°è¯•ä¸åŒçš„åˆ†éš”ç¬¦
                 separators = [',', '\t', ';', '|']
                 for sep in separators:
                     try:
                         df_temp = pd.read_csv(input_file, encoding=encoding, sep=sep)
                         # æ£€æŸ¥æ˜¯å¦æ­£ç¡®è§£æï¼ˆåˆ—æ•°å¤§äº1æˆ–è€…åˆ—åä¸åŒ…å«åˆ†éš”ç¬¦ï¼‰
                         if df_temp.shape[1] > 1 or not any(s in df_temp.columns[0] for s in ['\t', ',', ';', '|']):
                             df = df_temp
                             print(f"âœ… æˆåŠŸä½¿ç”¨ç¼–ç : {encoding}, åˆ†éš”ç¬¦: '{sep}'")
                             break
                     except:
                         continue
                 if df is not None:
                     break
             except UnicodeDecodeError:
                 print(f"âŒ ç¼–ç  {encoding} å¤±è´¥")
                 continue
             except Exception as e:
                 print(f"âŒ ä½¿ç”¨ç¼–ç  {encoding} æ—¶å‘ç”Ÿå…¶ä»–é”™è¯¯: {str(e)}")
                 continue
        
        if df is None:
            raise Exception("æ— æ³•ä½¿ç”¨ä»»ä½•ç¼–ç æ–¹å¼è¯»å–æ–‡ä»¶")
        
        # åŸºæœ¬ä¿¡æ¯
        print(f"\nğŸ“Š æ•°æ®åŸºæœ¬ä¿¡æ¯:")
        print(f"æ•°æ®å½¢çŠ¶: {df.shape}")
        print(f"è¡Œæ•°: {df.shape[0]:,}")
        print(f"åˆ—æ•°: {df.shape[1]}")
        
        # åˆ—ä¿¡æ¯
        print(f"\nğŸ“‹ åˆ—ä¿¡æ¯:")
        print(df.info())
        
        # æ•°æ®ç±»å‹ç»Ÿè®¡
        print(f"\nğŸ”¢ æ•°æ®ç±»å‹åˆ†å¸ƒ:")
        dtype_counts = df.dtypes.value_counts()
        for dtype, count in dtype_counts.items():
            print(f"{dtype}: {count} åˆ—")
        
        # ç¼ºå¤±å€¼ç»Ÿè®¡
        print(f"\nâŒ ç¼ºå¤±å€¼ç»Ÿè®¡:")
        missing_stats = df.isnull().sum()
        missing_percent = (missing_stats / len(df)) * 100
        missing_df = pd.DataFrame({
            'ç¼ºå¤±æ•°é‡': missing_stats,
            'ç¼ºå¤±ç™¾åˆ†æ¯”': missing_percent.round(2)
        })
        missing_df = missing_df[missing_df['ç¼ºå¤±æ•°é‡'] > 0].sort_values('ç¼ºå¤±æ•°é‡', ascending=False)
        
        if len(missing_df) > 0:
            print(missing_df)
        else:
            print("âœ… æ— ç¼ºå¤±å€¼")
        
        # æ•°å€¼åˆ—ç»Ÿè®¡
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) > 0:
            print(f"\nğŸ“ˆ æ•°å€¼åˆ—æè¿°æ€§ç»Ÿè®¡:")
            print(df[numeric_cols].describe())
        
        # æ–‡æœ¬åˆ—ç»Ÿè®¡
        text_cols = df.select_dtypes(include=['object']).columns
        if len(text_cols) > 0:
            print(f"\nğŸ“ æ–‡æœ¬åˆ—ä¿¡æ¯:")
            for col in text_cols[:10]:  # åªæ˜¾ç¤ºå‰10åˆ—
                unique_count = df[col].nunique()
                print(f"{col}: {unique_count} ä¸ªå”¯ä¸€å€¼")
                if unique_count <= 20:  # å¦‚æœå”¯ä¸€å€¼è¾ƒå°‘ï¼Œæ˜¾ç¤ºå‰å‡ ä¸ª
                    sample_values = df[col].value_counts().head(5)
                    print(f"  å‰5ä¸ªå€¼: {list(sample_values.index)}")
        
        # å‰å‡ è¡Œæ•°æ®é¢„è§ˆ
        print(f"\nğŸ‘€ æ•°æ®é¢„è§ˆ (å‰5è¡Œ):")
        print(df.head())
        
        # æè¿°æ€§åˆ†æ
        print(f"\nğŸ“Š æè¿°æ€§åˆ†æ:")
        print("=" * 50)
        
        # 1. ç»Ÿè®¡ä¸åŒDealer_typeçš„æ•°é‡
        print(f"\nğŸª ç»é”€å•†ç±»å‹(Dealer_type)åˆ†å¸ƒ:")
        dealer_type_counts = df['Dealer_type'].value_counts()
        for dealer_type, count in dealer_type_counts.items():
            percentage = (count / len(df)) * 100
            print(f"  {dealer_type}: {count:,} ä¸ª ({percentage:.1f}%)")
        
        # 2. æŒ‰Dealer Name Fcåˆ†ç»„ç»Ÿè®¡
        print(f"\nğŸ¢ æŒ‰ç»é”€å•†åç§°(Dealer Name Fc)åˆ†ç»„ç»Ÿè®¡:")
        dealer_stats = df.groupby('Dealer Name Fc').agg({
            'Dealer Name Fc': 'count',  # è®°å½•æ•°
            'Member Name': 'nunique',   # å”¯ä¸€æˆå‘˜å§“åæ•°
            'Member Code': 'nunique'    # å”¯ä¸€æˆå‘˜ä»£ç æ•°
        }).rename(columns={
            'Dealer Name Fc': 'è®°å½•æ•°',
            'Member Name': 'æˆå‘˜å§“åæ•°',
            'Member Code': 'æˆå‘˜ä»£ç æ•°'
        }).sort_values('è®°å½•æ•°', ascending=False)
        
        print(f"\nğŸ“ˆ ç»é”€å•†ç»Ÿè®¡æ±‡æ€» (å‰20å):")
        print(dealer_stats.head(20))
        
        # 3. ç»é”€å•†ç»Ÿè®¡æ¦‚è§ˆ
        print(f"\nğŸ“‹ ç»é”€å•†ç»Ÿè®¡æ¦‚è§ˆ:")
        print(f"  æ€»ç»é”€å•†æ•°é‡: {len(dealer_stats):,} ä¸ª")
        print(f"  å¹³å‡æ¯ä¸ªç»é”€å•†è®°å½•æ•°: {dealer_stats['è®°å½•æ•°'].mean():.1f}")
        print(f"  å¹³å‡æ¯ä¸ªç»é”€å•†æˆå‘˜æ•°: {dealer_stats['æˆå‘˜å§“åæ•°'].mean():.1f}")
        print(f"  æœ€å¤šè®°å½•çš„ç»é”€å•†: {dealer_stats.index[0]} ({dealer_stats.iloc[0]['è®°å½•æ•°']} æ¡è®°å½•)")
        print(f"  æœ€å°‘è®°å½•çš„ç»é”€å•†è®°å½•æ•°: {dealer_stats['è®°å½•æ•°'].min()}")
        
        # 4. æˆå‘˜ç»Ÿè®¡
        print(f"\nğŸ‘¥ æˆå‘˜ç»Ÿè®¡:")
        total_unique_members = df['Member Name'].nunique()
        total_unique_codes = df['Member Code'].nunique()
        print(f"  æ€»å”¯ä¸€æˆå‘˜å§“åæ•°: {total_unique_members:,}")
        print(f"  æ€»å”¯ä¸€æˆå‘˜ä»£ç æ•°: {total_unique_codes:,}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤çš„æˆå‘˜å§“åä½†ä¸åŒä»£ç 
        name_code_mapping = df.groupby('Member Name')['Member Code'].nunique()
        multiple_codes = name_code_mapping[name_code_mapping > 1]
        if len(multiple_codes) > 0:
            print(f"  æœ‰å¤šä¸ªä»£ç çš„æˆå‘˜å§“åæ•°: {len(multiple_codes)}")
            print(f"  ç¤ºä¾‹: {list(multiple_codes.head(3).index)}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤çš„æˆå‘˜ä»£ç ä½†ä¸åŒå§“å
        code_name_mapping = df.groupby('Member Code')['Member Name'].nunique()
        multiple_names = code_name_mapping[code_name_mapping > 1]
        if len(multiple_names) > 0:
            print(f"  æœ‰å¤šä¸ªå§“åçš„æˆå‘˜ä»£ç æ•°: {len(multiple_names)}")
            print(f"  ç¤ºä¾‹: {list(multiple_names.head(3).index)}")
        
        # è½¬æ¢ä¸ºJSONæ ¼å¼
        print(f"\nğŸ’¾ æ­£åœ¨è½¬æ¢ä¸ºJSONæ ¼å¼...")
        
        # å¤„ç†NaNå€¼ï¼Œè½¬æ¢ä¸ºNoneä»¥ä¾¿JSONåºåˆ—åŒ–
        df_json = df.where(pd.notnull(df), None)
        
        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        data_dict = {
            'metadata': {
                'total_rows': int(df.shape[0]),
                'total_columns': int(df.shape[1]),
                'columns': list(df.columns),
                'dtypes': {col: str(dtype) for col, dtype in df.dtypes.items()},
                'missing_values': {col: int(count) for col, count in missing_stats.items() if count > 0}
            },
            'data': df_json.to_dict('records')
        }
        
        # ä¿å­˜ä¸ºJSONæ–‡ä»¶
        print(f"æ­£åœ¨ä¿å­˜åˆ°: {output_file}")
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data_dict, f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ… åˆ†æå®Œæˆï¼")
        print(f"JSONæ–‡ä»¶å·²ä¿å­˜åˆ°: {output_file}")
        print(f"æ–‡ä»¶å¤§å°: {os.path.getsize(output_file) / 1024 / 1024:.2f} MB")
        
        return data_dict
        
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {input_file}")
        return None
    except Exception as e:
        print(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        return None

if __name__ == "__main__":
    result = explore_sales_info_data()
    if result:
        print("\nğŸ‰ è„šæœ¬æ‰§è¡ŒæˆåŠŸï¼")
    else:
        print("\nğŸ’¥ è„šæœ¬æ‰§è¡Œå¤±è´¥ï¼")